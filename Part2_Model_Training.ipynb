{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pvXBcx0KT1d",
        "outputId": "5ef9147e-a557-4afb-e3d7-2677b539b400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 2 is smaller than n_iter=3. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM trained in 54.63 seconds\n",
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [20:37:13] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost trained in 4.59 seconds\n",
            "Epoch 1/20\n",
            "525/525 - 2s - 5ms/step - accuracy: 0.6690 - loss: 0.7027 - val_accuracy: 0.8139 - val_loss: 0.4763\n",
            "Epoch 2/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.8268 - loss: 0.3985 - val_accuracy: 0.8930 - val_loss: 0.2554\n",
            "Epoch 3/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.8667 - loss: 0.2851 - val_accuracy: 0.9214 - val_loss: 0.2126\n",
            "Epoch 4/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.8785 - loss: 0.2512 - val_accuracy: 0.9090 - val_loss: 0.2020\n",
            "Epoch 5/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.8866 - loss: 0.2341 - val_accuracy: 0.9130 - val_loss: 0.1938\n",
            "Epoch 6/20\n",
            "525/525 - 1s - 3ms/step - accuracy: 0.8932 - loss: 0.2230 - val_accuracy: 0.9237 - val_loss: 0.1854\n",
            "Epoch 7/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.9005 - loss: 0.2152 - val_accuracy: 0.9273 - val_loss: 0.1796\n",
            "Epoch 8/20\n",
            "525/525 - 2s - 3ms/step - accuracy: 0.9023 - loss: 0.2089 - val_accuracy: 0.9318 - val_loss: 0.1760\n",
            "Epoch 9/20\n",
            "525/525 - 2s - 3ms/step - accuracy: 0.9054 - loss: 0.2060 - val_accuracy: 0.9316 - val_loss: 0.1741\n",
            "Epoch 10/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.9050 - loss: 0.2013 - val_accuracy: 0.9285 - val_loss: 0.1739\n",
            "Epoch 11/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.9079 - loss: 0.1989 - val_accuracy: 0.9306 - val_loss: 0.1700\n",
            "Epoch 12/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.9085 - loss: 0.1947 - val_accuracy: 0.9287 - val_loss: 0.1723\n",
            "Epoch 13/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.9110 - loss: 0.1932 - val_accuracy: 0.9266 - val_loss: 0.1713\n",
            "Epoch 14/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.9116 - loss: 0.1919 - val_accuracy: 0.9235 - val_loss: 0.1717\n",
            "Epoch 15/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.9125 - loss: 0.1900 - val_accuracy: 0.9295 - val_loss: 0.1642\n",
            "Epoch 16/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.9132 - loss: 0.1868 - val_accuracy: 0.9168 - val_loss: 0.1669\n",
            "Epoch 17/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.9116 - loss: 0.1877 - val_accuracy: 0.9276 - val_loss: 0.1635\n",
            "Epoch 18/20\n",
            "525/525 - 1s - 3ms/step - accuracy: 0.9150 - loss: 0.1843 - val_accuracy: 0.9254 - val_loss: 0.1657\n",
            "Epoch 19/20\n",
            "525/525 - 2s - 4ms/step - accuracy: 0.9119 - loss: 0.1877 - val_accuracy: 0.9357 - val_loss: 0.1630\n",
            "Epoch 20/20\n",
            "525/525 - 2s - 3ms/step - accuracy: 0.9163 - loss: 0.1812 - val_accuracy: 0.9168 - val_loss: 0.1693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FNN trained in 26.76 seconds\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "525/525 - 4s - 8ms/step - accuracy: 0.5623 - loss: 0.9928 - val_accuracy: 0.5728 - val_loss: 0.9787\n",
            "Epoch 2/20\n",
            "525/525 - 2s - 4ms/step - accuracy: 0.5689 - loss: 0.9850 - val_accuracy: 0.5728 - val_loss: 0.9799\n",
            "Epoch 3/20\n",
            "525/525 - 2s - 4ms/step - accuracy: 0.5689 - loss: 0.9837 - val_accuracy: 0.5728 - val_loss: 0.9790\n",
            "Epoch 4/20\n",
            "525/525 - 3s - 6ms/step - accuracy: 0.5689 - loss: 0.9838 - val_accuracy: 0.5728 - val_loss: 0.9789\n",
            "Epoch 5/20\n",
            "525/525 - 2s - 4ms/step - accuracy: 0.5689 - loss: 0.9835 - val_accuracy: 0.5728 - val_loss: 0.9781\n",
            "Epoch 6/20\n",
            "525/525 - 2s - 4ms/step - accuracy: 0.5689 - loss: 0.9836 - val_accuracy: 0.5728 - val_loss: 0.9800\n",
            "Epoch 7/20\n",
            "525/525 - 2s - 4ms/step - accuracy: 0.5689 - loss: 0.9830 - val_accuracy: 0.5728 - val_loss: 0.9797\n",
            "Epoch 8/20\n",
            "525/525 - 2s - 4ms/step - accuracy: 0.5689 - loss: 0.9831 - val_accuracy: 0.5728 - val_loss: 0.9784\n",
            "Epoch 9/20\n",
            "525/525 - 2s - 5ms/step - accuracy: 0.5689 - loss: 0.9823 - val_accuracy: 0.5728 - val_loss: 0.9792\n",
            "Epoch 10/20\n",
            "525/525 - 3s - 5ms/step - accuracy: 0.5689 - loss: 0.9820 - val_accuracy: 0.5728 - val_loss: 0.9788\n",
            "Epoch 11/20\n",
            "525/525 - 2s - 4ms/step - accuracy: 0.5689 - loss: 0.9816 - val_accuracy: 0.5728 - val_loss: 0.9793\n",
            "Epoch 12/20\n",
            "525/525 - 2s - 4ms/step - accuracy: 0.5689 - loss: 0.9827 - val_accuracy: 0.5728 - val_loss: 0.9787\n",
            "Epoch 13/20\n",
            "525/525 - 2s - 4ms/step - accuracy: 0.5689 - loss: 0.9817 - val_accuracy: 0.5728 - val_loss: 0.9791\n",
            "Epoch 14/20\n",
            "525/525 - 2s - 4ms/step - accuracy: 0.5689 - loss: 0.9815 - val_accuracy: 0.5728 - val_loss: 0.9787\n",
            "Epoch 15/20\n",
            "525/525 - 3s - 5ms/step - accuracy: 0.5689 - loss: 0.9821 - val_accuracy: 0.5728 - val_loss: 0.9797\n",
            "Epoch 16/20\n",
            "525/525 - 2s - 4ms/step - accuracy: 0.5689 - loss: 0.9819 - val_accuracy: 0.5728 - val_loss: 0.9799\n",
            "Epoch 17/20\n",
            "525/525 - 2s - 4ms/step - accuracy: 0.5689 - loss: 0.9815 - val_accuracy: 0.5728 - val_loss: 0.9795\n",
            "Epoch 18/20\n",
            "525/525 - 2s - 4ms/step - accuracy: 0.5689 - loss: 0.9816 - val_accuracy: 0.5728 - val_loss: 0.9801\n",
            "Epoch 19/20\n",
            "525/525 - 2s - 4ms/step - accuracy: 0.5689 - loss: 0.9817 - val_accuracy: 0.5728 - val_loss: 0.9796\n",
            "Epoch 20/20\n",
            "525/525 - 2s - 4ms/step - accuracy: 0.5689 - loss: 0.9809 - val_accuracy: 0.5728 - val_loss: 0.9802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM trained in 44.99 seconds\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "525/525 - 3s - 6ms/step - accuracy: 0.5639 - loss: 0.9982 - val_accuracy: 0.5728 - val_loss: 0.9826\n",
            "Epoch 2/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.5689 - loss: 0.9873 - val_accuracy: 0.5728 - val_loss: 0.9803\n",
            "Epoch 3/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.5689 - loss: 0.9861 - val_accuracy: 0.5728 - val_loss: 0.9797\n",
            "Epoch 4/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.5689 - loss: 0.9858 - val_accuracy: 0.5728 - val_loss: 0.9798\n",
            "Epoch 5/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.5689 - loss: 0.9842 - val_accuracy: 0.5728 - val_loss: 0.9818\n",
            "Epoch 6/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.5689 - loss: 0.9829 - val_accuracy: 0.5728 - val_loss: 0.9783\n",
            "Epoch 7/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.5689 - loss: 0.9829 - val_accuracy: 0.5728 - val_loss: 0.9795\n",
            "Epoch 8/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.5689 - loss: 0.9818 - val_accuracy: 0.5728 - val_loss: 0.9793\n",
            "Epoch 9/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.5689 - loss: 0.9821 - val_accuracy: 0.5728 - val_loss: 0.9784\n",
            "Epoch 10/20\n",
            "525/525 - 2s - 3ms/step - accuracy: 0.5689 - loss: 0.9811 - val_accuracy: 0.5728 - val_loss: 0.9794\n",
            "Epoch 11/20\n",
            "525/525 - 2s - 3ms/step - accuracy: 0.5689 - loss: 0.9811 - val_accuracy: 0.5728 - val_loss: 0.9788\n",
            "Epoch 12/20\n",
            "525/525 - 2s - 4ms/step - accuracy: 0.5688 - loss: 0.9805 - val_accuracy: 0.5728 - val_loss: 0.9796\n",
            "Epoch 13/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.5689 - loss: 0.9807 - val_accuracy: 0.5728 - val_loss: 0.9793\n",
            "Epoch 14/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.5689 - loss: 0.9797 - val_accuracy: 0.5728 - val_loss: 0.9797\n",
            "Epoch 15/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.5689 - loss: 0.9803 - val_accuracy: 0.5728 - val_loss: 0.9788\n",
            "Epoch 16/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.5688 - loss: 0.9796 - val_accuracy: 0.5728 - val_loss: 0.9783\n",
            "Epoch 17/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.5689 - loss: 0.9790 - val_accuracy: 0.5728 - val_loss: 0.9793\n",
            "Epoch 18/20\n",
            "525/525 - 1s - 2ms/step - accuracy: 0.5687 - loss: 0.9793 - val_accuracy: 0.5728 - val_loss: 0.9785\n",
            "Epoch 19/20\n",
            "525/525 - 1s - 3ms/step - accuracy: 0.5690 - loss: 0.9785 - val_accuracy: 0.5728 - val_loss: 0.9789\n",
            "Epoch 20/20\n",
            "525/525 - 2s - 3ms/step - accuracy: 0.5686 - loss: 0.9789 - val_accuracy: 0.5728 - val_loss: 0.9790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1D-CNN trained in 29.11 seconds\n",
            "FAST VERSION: All models trained and saved successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install packages if running in Colab\n",
        "# !pip install tensorflow keras xgboost\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "import xgboost as xgb\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Conv1D, MaxPooling1D, Flatten, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Step 1: Load preprocessed data\n",
        "data = pd.read_csv('/content/sample_data/drone_data_preprocessed.csv')\n",
        "X = data.drop('Label', axis=1).values\n",
        "y = data['Label'].values\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Optional: Use 30% of data for faster training\n",
        "X_train, _, y_train, _ = train_test_split(X_train, y_train, train_size=0.3, random_state=42, stratify=y_train)\n",
        "X_test, _, y_test, _ = train_test_split(X_test, y_test, train_size=0.3, random_state=42, stratify=y_test)\n",
        "\n",
        "# Feature scaling for SVM and FNN\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 2: SVM (fast hyperparameters)\n",
        "svm_param_grid = {\n",
        "    'kernel': ['rbf'],\n",
        "    'C': [1, 10],\n",
        "    'gamma': ['scale'],\n",
        "    'degree': [3]\n",
        "}\n",
        "svm = SVC(probability=True)\n",
        "svm_search = RandomizedSearchCV(svm, param_distributions=svm_param_grid, n_iter=3, cv=2, verbose=2, n_jobs=-1)\n",
        "start = time.time()\n",
        "svm_search.fit(X_train_scaled, y_train)\n",
        "end = time.time()\n",
        "print(f\"SVM trained in {end-start:.2f} seconds\")\n",
        "joblib.dump(svm_search, \"svm_model_fast.pkl\")\n",
        "\n",
        "# Step 3: XGBoost (fast hyperparameters)\n",
        "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "xgb_param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [3, 5],\n",
        "    'learning_rate': [0.05, 0.1],\n",
        "    'subsample': [0.8],\n",
        "    'colsample_bytree': [0.8]\n",
        "}\n",
        "xgb_search = RandomizedSearchCV(xgb_model, param_distributions=xgb_param_grid, n_iter=3, cv=2, verbose=2, n_jobs=-1)\n",
        "start = time.time()\n",
        "xgb_search.fit(X_train, y_train)\n",
        "end = time.time()\n",
        "print(f\"XGBoost trained in {end-start:.2f} seconds\")\n",
        "joblib.dump(xgb_search, \"xgb_model_fast.pkl\")\n",
        "\n",
        "# Step 4: Feedforward Neural Network (FNN)\n",
        "def create_fnn(input_dim, hidden_layers=[64, 32], dropout_rate=0.2, activation='relu', lr=0.001):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(input_dim,)))\n",
        "    for units in hidden_layers:\n",
        "        model.add(Dense(units, activation=activation))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(len(np.unique(y_train)), activation='softmax'))\n",
        "    optimizer = Adam(learning_rate=lr)\n",
        "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "fnn = create_fnn(X_train_scaled.shape[1])\n",
        "start = time.time()\n",
        "history_fnn = fnn.fit(X_train_scaled, y_train, validation_split=0.2, epochs=20, batch_size=32, verbose=2)\n",
        "end = time.time()\n",
        "print(f\"FNN trained in {end-start:.2f} seconds\")\n",
        "fnn.save(\"fnn_model_fast.h5\")\n",
        "\n",
        "# Step 5: Sequence data for LSTM/1D-CNN\n",
        "def create_sequences(X, y, time_steps=5):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(X)-time_steps):\n",
        "        X_seq.append(X[i:(i+time_steps)])\n",
        "        y_seq.append(y[i+time_steps])\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "time_steps = 5\n",
        "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train, time_steps)\n",
        "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test, time_steps)\n",
        "\n",
        "# Step 6: LSTM\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(32, input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
        "lstm_model.add(Dropout(0.2))\n",
        "lstm_model.add(Dense(len(np.unique(y_train)), activation='softmax'))\n",
        "lstm_model.compile(optimizer=Adam(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "start = time.time()\n",
        "history_lstm = lstm_model.fit(X_train_seq, y_train_seq, validation_split=0.2, epochs=20, batch_size=32, verbose=2)\n",
        "end = time.time()\n",
        "print(f\"LSTM trained in {end-start:.2f} seconds\")\n",
        "lstm_model.save(\"lstm_model_fast.h5\")\n",
        "\n",
        "# Step 7: 1D-CNN\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
        "cnn_model.add(MaxPooling1D(pool_size=2))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(32, activation='relu'))\n",
        "cnn_model.add(Dropout(0.2))\n",
        "cnn_model.add(Dense(len(np.unique(y_train)), activation='softmax'))\n",
        "cnn_model.compile(optimizer=Adam(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "start = time.time()\n",
        "history_cnn = cnn_model.fit(X_train_seq, y_train_seq, validation_split=0.2, epochs=20, batch_size=32, verbose=2)\n",
        "end = time.time()\n",
        "print(f\"1D-CNN trained in {end-start:.2f} seconds\")\n",
        "cnn_model.save(\"cnn_model_fast.h5\")\n",
        "\n",
        "print(\"FAST VERSION: All models trained and saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "35flArc7N9eH"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}